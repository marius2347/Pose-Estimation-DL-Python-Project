{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 22:31:01.118629: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-12 22:31:01.119400: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# import TF and TF Hub libraries.\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# load the input image.\n",
    "image_path = './image.jpg'\n",
    "\n",
    "# reads the image from the specified path as a raw byte string\n",
    "image = tf.io.read_file(image_path)\n",
    "\n",
    "# converts the raw byte string into a tensor representing the image, making it usable for further processing\n",
    "image = tf.compat.v1.image.decode_jpeg(image)\n",
    "\n",
    "# this line adds a new dimension at the start of the tensor shape, making it [1, height, width, channels]\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "# resize and pad the image to keep the aspect ratio and fit the expected size.\n",
    "image = tf.cast(tf.image.resize_with_pad(image, 256, 256), dtype=tf.int32)\n",
    "\n",
    "# Download the model from TF Hub.\n",
    "model = hub.load(\"https://www.kaggle.com/models/google/movenet/TensorFlow2/multipose-lightning/1\")\n",
    "\n",
    "# this retrieves the specific callable signature for running inference on the model\n",
    "movenet = model.signatures['serving_default']\n",
    "\n",
    "# Run model inference.\n",
    "outputs = movenet(image)\n",
    "\n",
    "# Output is a [1, 6, 56] tensor => retrieves the predicted keypoints, which are structured in a tensor with dimensions indicating the number of people and their respective keypoints\n",
    "keypoints = outputs['output_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model conversion complete and saved as model.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1720812954.404284   28722 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1720812954.404299   28722 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "2024-07-12 22:35:54.404429: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: ./movenet-tensorflow2-multipose-lightning-v1/\n",
      "2024-07-12 22:35:54.464816: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-07-12 22:35:54.464858: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: ./movenet-tensorflow2-multipose-lightning-v1/\n",
      "2024-07-12 22:35:54.787205: I tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
      "2024-07-12 22:35:55.144885: I tensorflow/cc/saved_model/loader.cc:218] Running initialization op on SavedModel bundle at path: ./movenet-tensorflow2-multipose-lightning-v1/\n",
      "2024-07-12 22:35:55.309915: I tensorflow/cc/saved_model/loader.cc:317] SavedModel load for tags { serve }; Status: success: OK. Took 905485 microseconds.\n",
      "2024-07-12 22:35:56.396454: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2996] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexStridedSlice\n",
      "Details:\n",
      "\ttf.StridedSlice(tensor<?x?x17xf32>, tensor<4xi32>, tensor<4xi32>, tensor<4xi32>) -> (tensor<?x?x1x17xf32>) : {begin_mask = 11 : i64, device = \"\", ellipsis_mask = 0 : i64, end_mask = 11 : i64, new_axis_mask = 4 : i64, shrink_axis_mask = 0 : i64}\n",
      "\ttf.StridedSlice(tensor<?x?x6xf32>, tensor<4xi32>, tensor<4xi32>, tensor<4xi32>) -> (tensor<?x?x6x1xf32>) : {begin_mask = 7 : i64, device = \"\", ellipsis_mask = 0 : i64, end_mask = 7 : i64, new_axis_mask = 8 : i64, shrink_axis_mask = 0 : i64}\n",
      "\ttf.StridedSlice(tensor<?x?xf32>, tensor<3xi32>, tensor<3xi32>, tensor<3xi32>) -> (tensor<?x?x1xf32>) : {begin_mask = 3 : i64, device = \"\", ellipsis_mask = 0 : i64, end_mask = 3 : i64, new_axis_mask = 4 : i64, shrink_axis_mask = 0 : i64}\n",
      "\ttf.StridedSlice(tensor<?x?xf32>, tensor<4xi32>, tensor<4xi32>, tensor<4xi32>) -> (tensor<?x?x1x1xf32>) : {begin_mask = 3 : i64, device = \"\", ellipsis_mask = 0 : i64, end_mask = 3 : i64, new_axis_mask = 12 : i64, shrink_axis_mask = 0 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorFlow SavedModel\n",
    "saved_model_dir = \"./movenet-tensorflow2-multipose-lightning-v1/\"  # Directory containing saved_model.pb\n",
    "\n",
    "# Create the TFLiteConverter object\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "\n",
    "# Enable TensorFlow ops that are not natively supported by TensorFlow Lite\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # TensorFlow Lite ops\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS  # Enable TensorFlow ops\n",
    "]\n",
    "\n",
    "# Optional: Optimization for size or latency\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "tflite_model_path = \"model.tflite\"\n",
    "with open(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"TFLite model conversion complete and saved as model.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details: [{'name': 'serving_default_input:0', 'index': 0, 'shape': array([1, 1, 1, 3], dtype=int32), 'shape_signature': array([ 1, -1, -1,  3], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Expected input shape: [1 1 1 3]\n",
      "Loading image from: ./image.jpg\n",
      "Original image shape: (1195, 1200, 3)\n",
      "Resizing image to: 1x1\n",
      "Input data shape after resizing: (1, 1, 1, 3)\n",
      "Inference output:\n",
      "[[[ 1.19312555e-01  3.21222320e-02  4.10582311e-03  9.23214406e-02\n",
      "    1.52409583e-01  1.84597715e-03 -5.12045510e-02  1.06847323e-01\n",
      "    3.64131120e-05  1.95450976e-01  4.48140353e-01  5.31197912e-08\n",
      "   -7.73408860e-02  3.29142034e-01  2.07998901e-14  3.80024672e-01\n",
      "    3.01253885e-01  9.79928378e-13 -5.20988554e-02  2.61832356e-01\n",
      "    4.78906031e-07 -4.07879561e-01  3.00798893e-01  1.68324711e-37\n",
      "   -6.32079720e-01  2.44954288e-01  0.00000000e+00 -1.27030402e-01\n",
      "    2.66909659e-01  0.00000000e+00 -2.68865794e-01  2.96452254e-01\n",
      "    0.00000000e+00  4.06778216e-01  2.78866775e-02  6.84836559e-05\n",
      "   -1.00698099e-02  2.06397861e-01  1.40400603e-04 -4.49317396e-01\n",
      "   -4.31794301e-02  0.00000000e+00 -4.59015906e-01  6.10294342e-02\n",
      "    0.00000000e+00 -1.02493063e-01  2.06207171e-01  0.00000000e+00\n",
      "   -8.16597790e-02  1.99298263e-01  6.95212123e-07  0.00000000e+00\n",
      "    9.63868856e-01  6.43053234e-01  9.63868856e-01  0.00000000e+00]\n",
      "  [ 1.19312555e-01  3.21222320e-02  4.10582311e-03  9.23214406e-02\n",
      "    1.52409583e-01  1.84597715e-03 -5.12045510e-02  1.06847323e-01\n",
      "    3.64131120e-05  1.95450976e-01  4.48140353e-01  5.31197912e-08\n",
      "   -7.73408860e-02  3.29142034e-01  2.07998901e-14  3.80024672e-01\n",
      "    3.01253885e-01  9.79928378e-13 -5.20988554e-02  2.61832356e-01\n",
      "    4.78906031e-07 -4.07879561e-01  3.00798893e-01  1.68324711e-37\n",
      "   -6.32079720e-01  2.44954288e-01  0.00000000e+00 -1.27030402e-01\n",
      "    2.66909659e-01  0.00000000e+00 -2.68865794e-01  2.96452254e-01\n",
      "    0.00000000e+00  4.06778216e-01  2.78866775e-02  6.84836559e-05\n",
      "   -1.00698099e-02  2.06397861e-01  1.40400603e-04 -4.49317396e-01\n",
      "   -4.31794301e-02  0.00000000e+00 -4.59015906e-01  6.10294342e-02\n",
      "    0.00000000e+00 -1.02493063e-01  2.06207171e-01  0.00000000e+00\n",
      "   -8.16597790e-02  1.99298263e-01  6.95212123e-07  4.48509097e-01\n",
      "    9.05467153e-01  1.00000000e+00  1.00000000e+00  0.00000000e+00]\n",
      "  [ 3.71699959e-01  1.23482145e-01  3.40172672e-03  3.83538365e-01\n",
      "    1.93920791e-01  4.21338540e-04  2.60842264e-01  1.76717818e-01\n",
      "    6.40598728e-07  4.98646706e-01  3.97373110e-01  4.13658974e-08\n",
      "    2.16920018e-01  3.43883902e-01  7.86666100e-17  6.17957771e-01\n",
      "    4.92560476e-01  1.35152645e-08  2.42321953e-01  5.04464209e-01\n",
      "    4.51521563e-11  4.06900465e-01  4.38836634e-01  5.09275619e-20\n",
      "   -6.32079720e-01  2.44954288e-01  0.00000000e+00 -1.27030402e-01\n",
      "    2.66909659e-01  0.00000000e+00 -2.68865794e-01  2.96452254e-01\n",
      "    0.00000000e+00  7.45418787e-01  3.36683095e-01  3.20036270e-05\n",
      "    2.92222679e-01  4.00456131e-01  6.41263381e-04 -4.49317396e-01\n",
      "   -4.31794301e-02  0.00000000e+00  1.48154750e-01  3.61381948e-01\n",
      "    7.84901240e-19 -1.02493063e-01  2.06207171e-01  0.00000000e+00\n",
      "    4.13121402e-01  5.76015040e-02  7.72315034e-05  2.64991015e-01\n",
      "    0.00000000e+00  5.85096478e-01  1.09273627e-01  0.00000000e+00]\n",
      "  [ 4.40074831e-01  4.29228127e-01  5.91055024e-03  4.54440773e-01\n",
      "    5.14466763e-01  2.62578041e-03  3.49146724e-01  4.89405513e-01\n",
      "    1.05488405e-03  5.24453163e-01  7.68378794e-01  1.48931875e-07\n",
      "    2.92571813e-01  7.48176217e-01  7.49247109e-10  6.22133493e-01\n",
      "    5.53753495e-01  3.80051511e-11  9.10707414e-02  5.24036765e-01\n",
      "    3.03552879e-05  2.29956925e-01  6.11723661e-01  1.38822106e-34\n",
      "   -1.22821324e-01  5.54741561e-01  1.94565724e-35 -1.27030402e-01\n",
      "    2.66909659e-01  0.00000000e+00 -2.68865794e-01  2.96452254e-01\n",
      "    0.00000000e+00  5.36006927e-01  1.50721192e-01  2.53617636e-05\n",
      "    9.18792933e-02  2.42584169e-01  1.28345446e-05 -4.49317396e-01\n",
      "   -4.31794301e-02  0.00000000e+00 -4.59015906e-01  6.10294342e-02\n",
      "    0.00000000e+00 -1.02493063e-01  2.06207171e-01  0.00000000e+00\n",
      "    5.09579182e-02  4.38575655e-01  5.88830007e-05  0.00000000e+00\n",
      "    3.52554232e-01  2.56418109e-01  4.20449466e-01  0.00000000e+00]\n",
      "  [ 1.19312555e-01  3.21222320e-02  4.10582311e-03  9.23214406e-02\n",
      "    1.52409583e-01  1.84597715e-03 -5.12045510e-02  1.06847323e-01\n",
      "    3.64131120e-05  1.95450976e-01  4.48140353e-01  5.31197912e-08\n",
      "   -7.73408860e-02  3.29142034e-01  2.07998901e-14  3.80024672e-01\n",
      "    3.01253885e-01  9.79928378e-13 -5.20988554e-02  2.61832356e-01\n",
      "    4.78906031e-07 -4.07879561e-01  3.00798893e-01  1.68324711e-37\n",
      "   -6.32079720e-01  2.44954288e-01  0.00000000e+00 -1.27030402e-01\n",
      "    2.66909659e-01  0.00000000e+00 -2.68865794e-01  2.96452254e-01\n",
      "    0.00000000e+00  4.53365445e-01  2.59210318e-01  4.86099656e-04\n",
      "    1.01895377e-01  2.75622487e-01  1.61364514e-04 -4.49317396e-01\n",
      "   -4.31794301e-02  0.00000000e+00 -4.59015906e-01  6.10294342e-02\n",
      "    0.00000000e+00 -1.02493063e-01  2.06207171e-01  0.00000000e+00\n",
      "    2.84818888e-01  6.23555854e-02  6.54430187e-05  0.00000000e+00\n",
      "    0.00000000e+00  5.53386807e-01  7.19091147e-02  0.00000000e+00]\n",
      "  [ 1.19312555e-01  3.21222320e-02  4.10582311e-03  9.23214406e-02\n",
      "    1.52409583e-01  1.84597715e-03 -5.12045510e-02  1.06847323e-01\n",
      "    3.64131120e-05  1.95450976e-01  4.48140353e-01  5.31197912e-08\n",
      "   -7.73408860e-02  3.29142034e-01  2.07998901e-14  3.80024672e-01\n",
      "    3.01253885e-01  9.79928378e-13 -5.20988554e-02  2.61832356e-01\n",
      "    4.78906031e-07 -4.07879561e-01  3.00798893e-01  1.68324711e-37\n",
      "   -6.32079720e-01  2.44954288e-01  0.00000000e+00 -1.27030402e-01\n",
      "    2.66909659e-01  0.00000000e+00 -2.68865794e-01  2.96452254e-01\n",
      "    0.00000000e+00  4.06778216e-01  2.78866775e-02  6.84836559e-05\n",
      "   -1.00698099e-02  2.06397861e-01  1.40400603e-04 -4.49317396e-01\n",
      "   -4.31794301e-02  0.00000000e+00 -4.59015906e-01  6.10294342e-02\n",
      "    0.00000000e+00 -1.02493063e-01  2.06207171e-01  0.00000000e+00\n",
      "   -8.16597790e-02  1.99298263e-01  6.95212123e-07  0.00000000e+00\n",
      "    1.44267902e-01  1.88682854e-01  1.52971074e-01  0.00000000e+00]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 22:40:40.964105: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-12 22:40:40.964302: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-07-12 22:40:40.964977: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_inter_op_parallelism which is not in the op definition: Op<name=StridedSlice; signature=input:T, begin:Index, end:Index, strides:Index -> output:T; attr=T:type; attr=Index:type,allowed=[DT_INT16, DT_INT32, DT_INT64]; attr=begin_mask:int,default=0; attr=end_mask:int,default=0; attr=ellipsis_mask:int,default=0; attr=new_axis_mask:int,default=0; attr=shrink_axis_mask:int,default=0> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node StridedSlice}}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Print input details to verify the expected input shape\n",
    "print(f\"Input details: {input_details}\")\n",
    "input_shape = input_details[0]['shape']  # Get the input shape\n",
    "print(f\"Expected input shape: {input_shape}\")\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = './image.jpg'\n",
    "print(f\"Loading image from: {image_path}\")\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was loaded properly\n",
    "if image is None:\n",
    "    raise ValueError(f\"Could not read the image from path: {image_path}\")\n",
    "\n",
    "print(f\"Original image shape: {image.shape}\")\n",
    "\n",
    "# Correctly resize the image\n",
    "input_height, input_width = input_shape[1:3]\n",
    "print(f\"Resizing image to: {input_width}x{input_height}\")\n",
    "input_data = cv2.resize(image, (input_width, input_height))\n",
    "\n",
    "# Convert image to the expected data type and normalize if required\n",
    "input_data = np.expand_dims(input_data, axis=0).astype(input_details[0]['dtype'])\n",
    "print(f\"Input data shape after resizing: {input_data.shape}\")\n",
    "\n",
    "# Normalization (if required by your model, you might need to adjust this)\n",
    "# input_data = input_data / 255.0\n",
    "\n",
    "# Set the tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the results\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Inference output:\")\n",
    "print(output_data) # X Y confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details: [{'name': 'serving_default_input:0', 'index': 0, 'shape': array([1, 1, 1, 3], dtype=int32), 'shape_signature': array([ 1, -1, -1,  3], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "# Print input tensor details\n",
    "print(f\"Input details: {input_details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 109\n",
      "Class probabilities: [[0.01781955 0.01633166 0.01588046 0.01734501 0.01841919 0.01584461\n",
      "  0.01502595 0.0175988  0.01581596 0.01922929 0.02475739 0.01581539\n",
      "  0.01463832 0.02197983 0.01581539 0.02312717 0.02137533 0.01581539\n",
      "  0.01501252 0.02054907 0.0158154  0.01051817 0.02136561 0.01581539\n",
      "  0.00840565 0.02020515 0.01581539 0.01392872 0.02065367 0.01581539\n",
      "  0.01208684 0.02127294 0.01581539 0.02375426 0.01626263 0.01581647\n",
      "  0.01565693 0.01944094 0.01581761 0.01009122 0.01514702 0.01581539\n",
      "  0.00999383 0.01681065 0.01581539 0.01427472 0.01943724 0.01581539\n",
      "  0.01457523 0.01930341 0.0158154  0.01581539 0.04146511 0.0300853\n",
      "  0.04146511 0.01581539]\n",
      " [0.01745252 0.01599528 0.01555337 0.01698776 0.01803982 0.01551826\n",
      "  0.01471647 0.01723633 0.01549021 0.01883323 0.02424747 0.01548965\n",
      "  0.01433682 0.02152712 0.01548965 0.02265083 0.02093507 0.01548965\n",
      "  0.01470331 0.02012583 0.01548965 0.01030153 0.02092554 0.01548965\n",
      "  0.00823252 0.019789   0.01548965 0.01364184 0.02022827 0.01548965\n",
      "  0.0118379  0.02083479 0.01548965 0.023265   0.01592768 0.01549071\n",
      "  0.01533445 0.01904052 0.01549182 0.00988338 0.01483504 0.01548965\n",
      "  0.00978799 0.01646441 0.01548965 0.01398071 0.01903689 0.01548965\n",
      "  0.01427503 0.01890582 0.01548966 0.02425641 0.03830724 0.04210522\n",
      "  0.04210522 0.01548965]\n",
      " [0.02146125 0.01674386 0.01484927 0.02171683 0.0179658  0.01480508\n",
      "  0.01920924 0.01765938 0.01479885 0.02436617 0.02201936 0.01479885\n",
      "  0.01838379 0.02087251 0.01479884 0.02745386 0.02421833 0.01479884\n",
      "  0.01885675 0.02450834 0.01479884 0.02223015 0.02295156 0.01479884\n",
      "  0.00786537 0.01890646 0.01479884 0.01303344 0.01932614 0.01479884\n",
      "  0.01130995 0.01990561 0.01479884 0.03118596 0.02072275 0.01479932\n",
      "  0.01982159 0.02208735 0.01480834 0.0094426  0.01417344 0.01479884\n",
      "  0.01716211 0.02124096 0.01479884 0.01335721 0.0181879  0.01479884\n",
      "  0.02236888 0.01567631 0.01479999 0.0192891  0.01479884 0.02656635\n",
      "  0.01650763 0.01479884]\n",
      " [0.02230722 0.02206657 0.01445075 0.02262999 0.02402998 0.01440336\n",
      "  0.02036835 0.02343524 0.01438075 0.02427115 0.03097605 0.01436559\n",
      "  0.019248   0.03035653 0.01436559 0.02676162 0.02499283 0.01436559\n",
      "  0.01573529 0.02426105 0.01436602 0.01807975 0.02648449 0.01436559\n",
      "  0.01270524 0.02501754 0.01436559 0.01265187 0.01876034 0.01436559\n",
      "  0.01097884 0.01932284 0.01436559 0.0245532  0.01670247 0.01436595\n",
      "  0.01574802 0.01830949 0.01436577 0.00916616 0.01375849 0.01436559\n",
      "  0.00907769 0.01526961 0.01436559 0.01296615 0.01765542 0.01436559\n",
      "  0.0151166  0.0222738  0.01436643 0.01436559 0.02043787 0.01856454\n",
      "  0.0218737  0.01436559]\n",
      " [0.01856391 0.01701387 0.01654382 0.01806955 0.0191886  0.01650648\n",
      "  0.01565362 0.01833394 0.01647663 0.02003254 0.02579156 0.01647604\n",
      "  0.01524979 0.02289799 0.01647604 0.02409325 0.02226823 0.01647604\n",
      "  0.01563963 0.02140746 0.01647604 0.01095754 0.0222581  0.01647604\n",
      "  0.00875677 0.02104917 0.01647604 0.01451056 0.02151643 0.01647604\n",
      "  0.01259174 0.02216156 0.01647604 0.02592668 0.0213514  0.01648405\n",
      "  0.01824338 0.02170471 0.01647869 0.01051276 0.01577975 0.01647604\n",
      "  0.01041129 0.01751287 0.01647604 0.01487101 0.02024918 0.01647604\n",
      "  0.02190524 0.01753612 0.01647711 0.01647604 0.01647604 0.02865402\n",
      "  0.01770445 0.01647604]\n",
      " [0.018901   0.01732281 0.01684422 0.01839766 0.01953703 0.0168062\n",
      "  0.01593786 0.01866685 0.01677582 0.02039629 0.02625988 0.01677521\n",
      "  0.0155267  0.02331377 0.01677521 0.02453073 0.02267257 0.01677521\n",
      "  0.01592362 0.02179617 0.01677522 0.0111565  0.02266226 0.01677521\n",
      "  0.00891578 0.02143138 0.01677521 0.01477404 0.02190712 0.01677521\n",
      "  0.01282038 0.02256397 0.01677521 0.02519587 0.0172496  0.01677636\n",
      "  0.01660713 0.02062079 0.01677756 0.01070365 0.01606628 0.01677521\n",
      "  0.01060034 0.01783087 0.01677521 0.01514104 0.02061686 0.01677521\n",
      "  0.01545979 0.02047491 0.01677522 0.01677521 0.01937861 0.02025871\n",
      "  0.019548   0.01677521]]\n"
     ]
    }
   ],
   "source": [
    "# Assuming the output is a 1D array of logits\n",
    "logits = output_data[0]\n",
    "\n",
    "# Apply softmax to get probabilities\n",
    "probabilities = tf.nn.softmax(logits).numpy()\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = np.argmax(probabilities) # identifies the index of the maximum value in the probabilities array.\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Class probabilities: {probabilities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
